#!/bin/bash

set -e -u -x

RUN_DIR=/var/vcap/sys/run/etcd
PIDFILE=${RUN_DIR}/etcd.pid

source /var/vcap/packages/pid_utils/pid_utils.sh

source /var/vcap/jobs/etcd/bin/etcd_bosh_utils.sh

wait_for_this_node_to_synchronize() {
  for i in $(seq <%= p("diego.etcd.log_sync_timeout_in_seconds") %>); do
    if /var/vcap/packages/etcd/etcdctl -C ${advertise_client_url} ls; then
      synced=true
      break
    fi
    sleep 1
  done
}


case $1 in

  start)

    pid_guard ${PIDFILE} "etcd"

    if ! mountpoint -q ${STORE_DIR}; then
      echo "$STORE_DIR must be a persistent disk"
      exit 1
    fi

    mkdir -p ${RUN_DIR}
    mkdir -p ${LOG_DIR}
    mkdir -p ${DATA_DIR}

    chown -R vcap:vcap ${RUN_DIR}
    chown -R vcap:vcap ${LOG_DIR}
    chown -R vcap:vcap ${DATA_DIR}

    # bump open file descriptor limit from default
    ulimit -n 65536

    prior_member_list=$(member_list)

    if [ -z "${prior_member_list}" ]; then
      cluster_state=new
      cluster="${this_node}"
    else
      cluster_state=existing
      existing_cluster=$(extract_cluster_from_member_list "${prior_member_list}")

      # If this node is not in the existing cluster, add it. It generally should
      # not be in the cluster, but if a prior shutdown failed to remove it, we
      # don't want to have it duplicated in the list (etcd server will fail to
      # start). Note extract_my_id determines membership solely based on IP, so
      # this logic is not future-proof against changing node names or ports.
      _my_id=$(extract_my_id "${prior_member_list}")
      if [ -z "${my_id}" ]; then
        cluster="${existing_cluster},${this_node}"
      fi

      # Only remove the DATA_DIR and leave the cluster if this is part of a
      # multi-node cluster to ensure a clean re-join. We will sync the data from
      # the other nodes. We can't do this for single-node cluster without data
      # loss.
      safe_teardown "${prior_member_list}"
    fi

    # Don't reuse $prior_member_list here because we may have changed it above
    # via the member_remove, do a fresh fetch of member_list
    my_id=$(extract_my_id member_list)
    if [ -z "${my_id}" ] && [ ${cluster_state} == "existing" ]; then
      member_add
    fi

    # Sleep to allow member_add to propagate to entire cluster because starting
    # the server subsequently expects all peers to agree on the cluster members
    sleep 2

    chpst -u vcap:vcap /var/vcap/packages/etcd/etcd                                             \
        --name                        ${node_name}                                              \
        --data-dir                    ${DATA_DIR}                                               \
        --heartbeat-interval          <%= p("diego.etcd.heartbeat_interval_in_milliseconds") %> \
        --election-timeout            <%= p("diego.etcd.election_timeout_in_milliseconds") %>   \
        --listen-peer-urls            ${listen_peer_url}                                        \
        --listen-client-urls          ${listen_client_url}                                      \
        --initial-advertise-peer-urls ${advertise_peer_url}                                     \
        --advertise-client-urls       ${advertise_client_url}                                   \
        --initial-cluster             ${cluster}                                                \
        --initial-cluster-state       ${cluster_state}                                          \
        2> >(tee -a ${LOG_DIR}/etcd.stderr.log | logger -t vcap.etcd)                           \
        1> >(tee -a ${LOG_DIR}/etcd.stdout.log | logger -t vcap.etcd) &

    etcd_pid=$!

    synced=false
    wait_for_this_node_to_synchronize # mutates $synced

    if ${synced}; then
      echo ${etcd_pid} > ${PIDFILE}
      wait ${etcd_pid}
    else
      safe_teardown "${prior_member_list}"
      kill -9 ${etcd_pid}
      exit 1
    fi

    ;;

  stop)

    kill_and_wait ${PIDFILE}

    ;;

  *)

    echo "Usage: etcd_ctl {start|stop}"

    ;;

esac
